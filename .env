TRAINING_CAPTION_EXTENSION=.txt
TRAINING_CLIP_SKIP=2
TRAINING_GRADIENT_ACCUMULATION_STEPS=1
TRAINING_LEARNING_RATE=0.0001
TRAINING_LOGGING_DIR=log
TRAINING_LR_SCHEDULER=cosine_with_restarts
TRAINING_MAX_BUCKET_RESO=768
TRAINING_MAX_DATA_LOADER_N_WORKERS=12
TRAINING_MAX_TRAIN_EPOCHS=80
TRAINING_MIN_BUCKET_RESO=320
TRAINING_MIXED_PRECISION=fp16
TRAINING_NETWORK_ALPHA=128
TRAINING_NETWORK_DIM=160
TRAINING_NETWORK_MODULE=networks.lora
TRAINING_NUM_CPU_THREADSPERPROCESS=20
TRAINING_NUM_MACHINES=1
TRAINING_NUM_PROCESSES=1
TRAINING_OUTPUT_DIR=/stable/training_outputs
TRAINING_OUTPUT_NAME=$LORA_NAME
TRAINING_PRETRAINED_MODEL_NAME_OR_PATH=/stable/base_models/
TRAINING_PRIOR_LOSS_WEIGHT=1
TRAINING_RESOLUTION=512
TRAINING_SAVE_EVERY_N_EPOCHS=5
TRAINING_SAVE_MODEL_AS=safetensors
TRAINING_SAVE_PRECISION=fp16
TRAINING_T_ENCODER_LR=4e-05
TRAINING_TRAIN_BATCH_SIZE=16
TRAINING_TRAIN_DATA_DIR=/stable/training_data
TRAINING_UNET_LR=0.0001
